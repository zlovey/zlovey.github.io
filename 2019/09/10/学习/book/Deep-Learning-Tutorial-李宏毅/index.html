<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/cat_32.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/cat_16.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="ä¹¦ç±ï¼šDeep Learning Tutorial -æå®æ¯… Hung-yi Lee Outline  Lecture I: Introduction of Deep Learning  Lecture II: Tips for Training Deep Neural Network  Lecture III: Variants of Neural Network  Lecture IV: Ne">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep-Learning-Tutorial_æå®æ¯…">
<meta property="og:url" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/index.html">
<meta property="og:site_name" content="Garden">
<meta property="og:description" content="ä¹¦ç±ï¼šDeep Learning Tutorial -æå®æ¯… Hung-yi Lee Outline  Lecture I: Introduction of Deep Learning  Lecture II: Tips for Training Deep Neural Network  Lecture III: Variants of Neural Network  Lecture IV: Ne">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/neuron.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/neuron2.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/full_connect.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/full_connect2.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/softmax_layer.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/nn-example.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Gradient%20Descent.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Gradient_Descent2.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/recipe.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/example-loss-function.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/mini-batch.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Maxout.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Momentum.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Momentum1.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/early-stop.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/weight-decay.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/dropout1.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/CNNç½‘ç»œç»“æ„.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/å·ç§¯æ ¸.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/å·ç§¯-è¾“å…¥.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/slide1.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/slide2.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/pk2y72bp1x.gif">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/å·ç§¯filter1.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/2filter.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/é›¶å¡«å…….png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/max-pooling.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/rnn-slot.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/rnn-str.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/bi-rnn.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/lstm-str.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/lstm-pa.png">
<meta property="og:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Ultra-deep.png">
<meta property="og:updated_time" content="2020-04-06T08:40:13.076Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep-Learning-Tutorial_æå®æ¯…">
<meta name="twitter:description" content="ä¹¦ç±ï¼šDeep Learning Tutorial -æå®æ¯… Hung-yi Lee Outline  Lecture I: Introduction of Deep Learning  Lecture II: Tips for Training Deep Neural Network  Lecture III: Variants of Neural Network  Lecture IV: Ne">
<meta name="twitter:image" content="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/neuron.png">






  <link rel="canonical" href="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Deep-Learning-Tutorial_æå®æ¯… | Garden</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/zlovey"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"></a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Garden</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="åˆ‡æ¢å¯¼èˆªæ ">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />é¦–é¡µ</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />å…³äº</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />æ ‡ç­¾</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />åˆ†ç±»</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />å½’æ¡£</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-schedule">
    <a href="/schedule/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />æ—¥ç¨‹è¡¨</a>
  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lavi">
      <meta itemprop="description" content="è¿›åŒ–ing">
      <meta itemprop="image" content="/images/headimg/14.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garden">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Deep-Learning-Tutorial_æå®æ¯…
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              
                
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2019-09-10 15:19:09" itemprop="dateCreated datePublished" datetime="2019-09-10T15:19:09+08:00">2019-09-10</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">æ›´æ–°äº</span>
                
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-04-06 16:40:13" itemprop="dateModified" datetime="2020-04-06T16:40:13+08:00">2020-04-06</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/å­¦ä¹ /" itemprop="url" rel="index"><span itemprop="name">å­¦ä¹ </span></a></span>

                
                
                  ï¼Œ
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/å­¦ä¹ /ä¹¦ç±å­¦ä¹ ç¬”è®°/" itemprop="url" rel="index"><span itemprop="name">ä¹¦ç±å­¦ä¹ ç¬”è®°</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>ä¹¦ç±ï¼šDeep Learning Tutorial -æå®æ¯… Hung-yi Lee</p>
<p><strong>Outline</strong> </p>
<p><strong>Lecture I: Introduction of Deep Learning</strong> </p>
<p><strong>Lecture II: Tips for Training Deep Neural Network</strong> </p>
<p><strong>Lecture III: Variants of Neural Network</strong> </p>
<p><strong>Lecture IV: Next Wave</strong><a id="more"></a></p>
<hr>
<h4 id="Lecture-I-Introduction-of-Deep-Learning"><a href="#Lecture-I-Introduction-of-Deep-Learning" class="headerlink" title="Lecture I: Introduction of  Deep Learning"></a><strong>Lecture I: Introduction of  Deep Learning</strong></h4><ul>
<li><strong>Introduction of Deep Learning</strong> </li>
<li><strong>Why Deep?</strong> </li>
<li><strong>â€œHello Worldâ€ for Deep Learning</strong></li>
</ul>
<hr>
<h5 id="Introduction-of-Deep-Learning"><a href="#Introduction-of-Deep-Learning" class="headerlink" title="Introduction of Deep Learning"></a>Introduction of Deep Learning</h5><ul>
<li><h6 id="Three-Steps-for-Deep-Learning"><a href="#Three-Steps-for-Deep-Learning" class="headerlink" title="Three Steps for Deep Learning"></a>Three Steps for Deep Learning</h6><ul>
<li>Step 1:  define a set of function  </li>
<li>Step 2:  goodness of function </li>
<li>Step 3: pick the best function </li>
</ul>
</li>
</ul>
<hr>
<ul>
<li><p>Step 1:  define a set of function  </p>
<ul>
<li><p>Neural Network </p>
<ul>
<li><p><strong><em>Neuron</em></strong>ç¥ç»å…ƒ</p>
<ul>
<li><p>$z=a_1w_1+\cdots+a_kw_k+\cdots+a_Kw_K+b$</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/neuron.png" alt="neuron"></p>
</li>
<li><p>ä¸¾ä¾‹        </p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/neuron2.png" alt="neuron2"></p>
</li>
</ul>
</li>
<li><p><strong>Neural Network</strong> ç¥ç»ç½‘ç»œ</p>
<ul>
<li><p>Each neurons can have different values of weights and biases.</p>
</li>
<li><p>Weights and biases are network parameters $\theta$</p>
</li>
<li><p>Fully Connect Feedforward Network </p>
<ul>
<li>æ¯ä¸ªç¥ç»å…ƒéƒ½ä¸ä¸‹ä¸€å±‚å…¨éƒ¨çš„ç¥ç»å…ƒè¿æ¥å³fully connect</li>
<li>ä¸¾ä¾‹ï¼ˆä¸­é—´èŠ‚ç‚¹å³ä¸ºç¥ç»å…ƒï¼‰<img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/full_connect.png" alt="full_connect"></li>
<li>å³$f\begin{bmatrix} 1\\ -1\end{bmatrix}=\begin{bmatrix} 0.62\\ 0.85\end{bmatrix}$</li>
<li>ä¸€èˆ¬åœ°ï¼Œå…¨è¿æ¥ç½‘ç»œå¦‚ä¸‹å›¾ç»“æ„<img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/full_connect2.png" alt="full_connect2"></li>
</ul>
</li>
<li><p>Output Layer </p>
<ul>
<li>Softmax layer <ul>
<li>Softmaxå‡½æ•°å°†å¤šä¸ªæ ‡é‡æ˜ å°„ä¸ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œå…¶è¾“å‡ºçš„æ¯ä¸€ä¸ªå€¼èŒƒå›´åœ¨(0,1)</li>
<li>softmaxå‡½æ•°ç»å¸¸ç”¨åœ¨ç¥ç»ç½‘ç»œçš„æœ€åä¸€å±‚ï¼Œä½œä¸ºè¾“å‡ºå±‚ï¼Œè¿›è¡Œå¤šåˆ†ç±»</li>
<li>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œzä¸ºoutputå±‚çš„è¾“å…¥ï¼Œyä¸ºè¾“å‡ºï¼Œé€‰å–è¾“å‡ºæ¦‚ç‡æœ€å¤§çš„ä¸ºåˆ†ç±»ç»“æœ<img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/softmax_layer.png" alt="softmax_layer"></li>
</ul>
</li>
</ul>
</li>
<li><p>Example</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/nn-example.png" alt="nn-example"></p>
</li>
<li><p>purpose</p>
<p>decide the network structure to let a good function in your function set.</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>Step 2:  goodness of function <ul>
<li>Training Data</li>
<li>Learning Target</li>
<li>Loss: A good function should make the loss of all examples as small as possible. </li>
<li>Total Loss  $L=\sum_{r=1}^{R}l_r$</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li><p>Step 3: pick the best function </p>
<ul>
<li><p>How to pick the best function</p>
<ul>
<li><p>Gradient Descent</p>
<ul>
<li><p>Network parameters ğœƒ = {ğ‘¤1, ğ‘¤2, â‹¯ , ğ‘1, ğ‘2, â‹¯}</p>
</li>
<li><p>Pick an initial value for w</p>
</li>
<li><p>Compute  ğœ•ğ¿/ğœ•ğ‘¤</p>
<ul>
<li>Negative: Increase w</li>
<li>Positive: Decrease w</li>
</ul>
</li>
<li><p>Compute:  $w=w-\eta ğœ•ğ¿/ğœ•ğ‘¤$ ($\eta$â€“learning rateå­¦ä¹ ç‡)</p>
</li>
<li><p>Repeat Compute Until ğœ•ğ¿/ğœ•ğ‘¤ is approximately small (when update is little)ã€æ”¹å˜å¾ˆå°ï¼Œæ¥è¿‘0ã€‘</p>
</li>
<li><p>å›¾ä¾‹</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Gradient Descent.png" alt="Gradient Descent"></p>
</li>
<li><p>ç­‰é«˜å›¾</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Gradient_Descent2.png" alt="Gradient_Descent2"></p>
</li>
<li><p>Gradient descent never guarantee global minimumï¼ˆå±€éƒ¨æœ€ä½å¹¶ä¸æ˜¯å…¨å±€æœ€ä½ï¼‰</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h5 id="Why-Deep"><a href="#Why-Deep" class="headerlink" title="Why Deep?"></a><strong>Why Deep?</strong></h5><ul>
<li>Deeper is Better</li>
<li>A hidden layer network can represent any continuous function. </li>
<li>Modularization</li>
</ul>
<hr>
<h5 id="â€œHello-Worldâ€-for-Deep-Learning"><a href="#â€œHello-Worldâ€-for-Deep-Learning" class="headerlink" title="â€œHello Worldâ€ for Deep Learning"></a><strong>â€œHello Worldâ€ for Deep Learning</strong></h5><ul>
<li>Keras, TensorFlow, </li>
</ul>
<hr>
<h4 id="Lecture-II-Tips-for-Training-DNN"><a href="#Lecture-II-Tips-for-Training-DNN" class="headerlink" title="Lecture II: Tips for Training DNN"></a><strong>Lecture II: Tips for Training DNN</strong></h4><ul>
<li><strong>Good Results on Training Data?</strong></li>
<li><strong>Good Results on Testing Data?</strong> </li>
</ul>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/recipe.png" alt="recipe"></p>
<hr>
<h5 id="Good-Results-on-Training-Data"><a href="#Good-Results-on-Training-Data" class="headerlink" title="Good Results on Training Data?"></a><strong>Good Results on Training Data?</strong></h5><ul>
<li><strong>Choosing proper loss</strong></li>
<li><strong>Mini-batch</strong></li>
<li><strong>New activation function</strong></li>
<li><strong>Adaptive Learning Rate</strong></li>
<li><strong>Momentum</strong></li>
</ul>
<hr>
<h6 id="Choosing-proper-loss"><a href="#Choosing-proper-loss" class="headerlink" title="Choosing proper loss"></a><strong>Choosing proper loss</strong></h6><ul>
<li><p>for example: Square Error, Cross Entropy</p>
</li>
<li><p>ç”¨ä¸€ä¸ªæ•°æ®é›†åšæµ‹è¯•</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/example-loss-function.png" alt="example-loss-function"></p>
<ul>
<li>å¦‚ä¸Šï¼Œbetter to choose cross entropy</li>
</ul>
</li>
</ul>
<hr>
<h6 id="Mini-batch"><a href="#Mini-batch" class="headerlink" title="Mini-batch"></a><strong>Mini-batch</strong></h6><ul>
<li>æ¯æ¬¡ç”¨ä¸€éƒ¨åˆ†æ ·æœ¬æ¥æ›´æ–°å‚æ•°ï¼Œå³ batch_size</li>
</ul>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/mini-batch.png" alt="mini-batch"></p>
<ul>
<li>Mini-batchè¾ƒå…¨batchè€Œè¨€ä¸ç¨³å®š</li>
<li>Mini-batch is faster</li>
</ul>
<hr>
<h6 id="New-activation-function"><a href="#New-activation-function" class="headerlink" title="New activation function"></a><strong>New activation function</strong></h6><ul>
<li>Deeper usually does not imply better.</li>
<li>Vanishing Gradient Problemæ¢¯åº¦æ¶ˆå¤±é—®é¢˜<ul>
<li>åœ¨ç¥ç»ç½‘ç»œä¸­ï¼Œå½“å‰é¢éšè—å±‚çš„å­¦ä¹ é€Ÿç‡ä½äºåé¢éšè—å±‚çš„å­¦ä¹ é€Ÿç‡ï¼Œå³éšç€éšè—å±‚æ•°ç›®çš„å¢åŠ ï¼Œåˆ†ç±»å‡†ç¡®ç‡åè€Œä¸‹é™äº†ã€‚è¿™ç§ç°è±¡å«åšæ¶ˆå¤±çš„æ¢¯åº¦é—®é¢˜ã€‚</li>
<li>ä»æ±‚å¯¼ç»“æœå¯ä»¥çœ‹å‡ºï¼ŒSigmoidå¯¼æ•°çš„å–å€¼èŒƒå›´åœ¨0~0.25ä¹‹é—´ï¼Œè€Œæˆ‘ä»¬åˆå§‹åŒ–çš„ç½‘ç»œæƒå€¼$|w|$é€šå¸¸éƒ½å°äº1ï¼Œå› æ­¤ï¼Œå½“å±‚æ•°å¢å¤šæ—¶ï¼Œå°äº0çš„å€¼ä¸æ–­ç›¸ä¹˜ï¼Œæœ€åå°±å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±çš„æƒ…å†µå‡ºç°ã€‚åŒç†ï¼Œæ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ä¹Ÿå°±å¾ˆæ˜æ˜¾äº†ï¼Œå°±æ˜¯å½“æƒå€¼$|w|$è¿‡å¤§æ—¶ï¼Œå¯¼è‡´ $|\sigmaâ€™(z)w| &gt; 1$ï¼Œæœ€åå¤§äº1çš„å€¼ä¸æ–­ç›¸ä¹˜ï¼Œå°±ä¼šäº§ç”Ÿæ¢¯åº¦çˆ†ç‚¸ã€‚</li>
</ul>
</li>
<li>ReLUï¼ˆ Rectified Linear Unit ï¼‰<ul>
<li>æ¿€æ´»å‡½æ•°çš„å¯¼æ•°ä¸º1ï¼Œä¸ä¼šå‡ºç°æ¢¯åº¦æ¶ˆå¤±é—®é¢˜</li>
<li>ä¼˜ç‚¹ï¼š1)ä¸é¥±å’Œï¼›2)è®¡ç®—æ•ˆç‡é«˜ï¼›3)æ”¶æ•›é€Ÿåº¦å¿«</li>
</ul>
</li>
<li>åŸå‹Maxout:<ul>
<li>å³å–æœ€å¤§çš„å€¼ä½œä¸ºè¾“å‡ºï¼š<img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Maxout.png" alt="Maxout"></li>
<li>ReLU is a special cases of Maxout</li>
</ul>
</li>
</ul>
<hr>
<h6 id="Adaptive-Learning-Rate"><a href="#Adaptive-Learning-Rate" class="headerlink" title="Adaptive Learning Rate"></a><strong>Adaptive Learning Rate</strong></h6><ul>
<li><p>Set the learning rate Î· carefully</p>
<ul>
<li>If learning rate is too largeâ€”&gt;Total loss may not decrease after each update</li>
<li>If learning rate is too smallâ€”&gt;Training would be too slow</li>
</ul>
</li>
<li><p>Popular &amp; Simple Idea: Reduce the learning rate by some factor every few epochs.</p>
<ul>
<li>è®­ç»ƒå¼€å§‹æ—¶ï¼Œè·ç¦»æœ€å°ç‚¹å¾ˆè¿œï¼Œäºæ˜¯é€‰å–è¾ƒå¤§çš„å­¦ä¹ ç‡</li>
<li>ç»è¿‡ä¸€äº›epochä¹‹åå¯ä»¥é€‚å½“å‡å°å­¦ä¹ ç‡çš„å€¼</li>
</ul>
</li>
<li><p>Adagradâ€”â€”é”™è¯¯æ–¹å‘çš„é˜»åŠ›åŠ å¤§ï¼ˆä¸€åŒä¸å¥½èµ°è·¯çš„é‹å­â€”â€”ä½¿å…¶æƒ³è¦å¿«é€Ÿåˆ°è¾¾ç»ˆç‚¹ï¼‰</p>
<ul>
<li><p>è§£å†³ä¸åŒå‚æ•°åº”è¯¥ä½¿ç”¨ä¸åŒçš„æ›´æ–°é€Ÿç‡çš„é—®é¢˜</p>
</li>
<li><p>$wâ† w-\eta_w \partial L/\partial w$</p>
</li>
<li><p>$\eta_w$æ˜¯æ ¹æ®å­¦ä¹ ç‡å˜æ¢çš„å˜é‡<br>$$<br>\eta_w=\frac{\eta}{\sqrt{\sum_{i=0}^{t}{(g^i)^2}}}<br>$$<br>$\eta$æ˜¯å¸¸æ•°ï¼Œ$g^i$æ˜¯åœ¨å®Œæˆç¬¬iæ¬¡æ›´æ–°åçš„$ğœ•L/ğœ•w$å€¼</p>
</li>
</ul>
</li>
<li><p>RMSpropã€Adamâ€”â€”ä¸€åŒä¸å¥½èµ°è·¯çš„é‹+ä¸‹å¡ï¼ˆadamä¸€èˆ¬æ›´å¥½ï¼‰</p>
</li>
<li><p>å…¶ä»–çš„ä¸€äº›æ”¹å–„å­¦ä¹ ç‡çš„æ–¹æ³•ï¼š</p>
<ul>
<li>Adadelta ã€Nadamç­‰</li>
</ul>
</li>
</ul>
<hr>
<h6 id="MomentumåŠ¨é‡â€”â€”ä¸‹å¡"><a href="#MomentumåŠ¨é‡â€”â€”ä¸‹å¡" class="headerlink" title="MomentumåŠ¨é‡â€”â€”ä¸‹å¡"></a><strong>MomentumåŠ¨é‡â€”â€”ä¸‹å¡</strong></h6><ul>
<li><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¾ˆéš¾å†³å®šä»€ä¹ˆæ—¶å€™æ˜¯æœ€ä¼˜çš„ç»“æœï¼š</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Momentum.png" alt="Momentum"></p>
</li>
<li><p>å¯ä»¥æ·»åŠ åŠ¨é‡ï¼Œä½¿å¾—åœ¨ä¸‹é™çš„è¿‡ç¨‹å€¾å‘äºè¾¾åˆ°æœ€ä½ç‚¹ï¼š</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Momentum1.png" alt="Momentum1"></p>
</li>
<li><p>å¯ä»¥ä½¿ç”¨Adam</p>
<ul>
<li>Adam=RMSProp (Advanced Adagrad) + Momentum</li>
</ul>
</li>
</ul>
<hr>
<h5 id="Good-Results-on-Testing-Data"><a href="#Good-Results-on-Testing-Data" class="headerlink" title="Good Results on Testing Data?"></a><strong>Good Results on Testing Data?</strong></h5><ul>
<li><strong>Early Stopping</strong></li>
<li><strong>Weight Decay</strong></li>
<li><strong>Dropout</strong></li>
<li><strong>Network Structure</strong></li>
</ul>
<hr>
<h6 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a><strong>Overfitting</strong></h6><ul>
<li>åŸå› ï¼šè®­ç»ƒé›†ä¸æµ‹è¯•é›†çš„åˆ†å¸ƒä¸ä¸€æ ·</li>
<li>æ–¹æ³•ï¼š<ul>
<li>å¢åŠ æ›´å¤šçš„è®­ç»ƒé›†</li>
<li>åˆ›é€ æ›´å¤šçš„è®­ç»ƒé›†ï¼ˆå¦‚æœåŸæœ¬æ²¡æœ‰æ›´å¤šçš„æ•°æ®äº†ï¼‰</li>
</ul>
</li>
</ul>
<hr>
<h6 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a><strong>Early Stopping</strong></h6><ul>
<li>ç®€å•çš„å›¾ç¤ºï¼š</li>
</ul>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/early-stop.png" alt="early-stop"></p>
<hr>
<h6 id="Weight-Decay-regularization-L2æ­£åˆ™åŒ–"><a href="#Weight-Decay-regularization-L2æ­£åˆ™åŒ–" class="headerlink" title="Weight Decay(regularization  L2æ­£åˆ™åŒ–)"></a><strong>Weight Decay(regularization  L2æ­£åˆ™åŒ–)</strong></h6><ul>
<li>prunes out the useless link between neurons. ç±»ä¼¼å‰ªæï¼Œå¯¹æ²¡æœ‰ç”¨æˆ–è€…ç”¨å¤„å¾ˆå°çš„ç¥ç»å…ƒè¿›è¡Œåˆ å‡</li>
<li>å›¾ç¤º</li>
</ul>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/weight-decay.png" alt="weight-decay"></p>
<ul>
<li>å®ç°(Cæ˜¯cost function)<ul>
<li>$$ C = C_0 + \frac{\lambda}{2n} \sum_w w^2$$</li>
<li>$$ \frac{\partial C}{\partial w} = \frac{\partial C_0}{\partial w} + \frac{\lambda}{n} w $$</li>
<li>$w=w-\eta\frac{\partial C}{\partial w}$</li>
<li>è®©weightå˜å°ä¸€ç‚¹ï¼Œå¸¦æ¥çš„å¥½å¤„æ˜¯å¯ä»¥æ˜¯æ•´ä¸ªç¥ç»ç½‘ç»œå¯¹è¾“å…¥ä¸­çš„å™ªéŸ³ï¼ˆæˆ–è€…ä¸€ç‚¹ç‚¹å˜åŒ–ï¼‰ä¸è¦é‚£ä¹ˆæ•æ„Ÿï¼›weightå¤ªå¤§ï¼Œå…¶å¯¹åº”çš„è¾“å…¥çš„ä¸€ç‚¹ç‚¹å˜åŒ–å°±ä¼šèµ·åˆ°ä¸»å¯¼ä½œç”¨ï¼Œè¿›è€Œæ˜¾è‘—æ”¹å˜è¾“å‡ºã€‚</li>
<li>ä»å…¬å¼æ¥çœ‹ï¼Œweight decayå¯¹äºæ¯”è¾ƒå¤§çš„weightï¼Œdecayçš„æ›´å¤šï¼Œæ¯”è¾ƒå°çš„weightï¼Œdecayè¾ƒå°ï¼›è¿™å°±ç›¸å½“äºï¼Œweightè¶Šå¤§ï¼Œæƒ©ç½šè¶Šå¤§ï¼Œå³å¯ä»¥æ›´æœ‰æ•ˆçš„å‡å°‘Costå‡½æ•°ã€‚</li>
<li>è®©ç¥ç»ç½‘ç»œå€¾å‘äºå½¢æˆæ›´ç®€å•çš„ï¼Œâ€œæ–œç‡â€æ›´å°çš„æ¨¡å‹ï¼›æ¯”å¦‚ä¸€ä¸ªéçº¿æ€§æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å¾ˆå¤æ‚çš„é«˜é˜¶å¤šé¡¹å¼æ¥è¡¨ç¤ºï¼Œä¹Ÿå¯ä»¥å®¹å¿ä¸€äº›å™ªéŸ³ï¼Œé€šè¿‡ç®€å•çš„ä½é˜¶å¤šé¡¹å¼æ¥è¡¨ç¤ºï¼Œç”šè‡³ç›´æ¥ä½¿ç”¨çº¿æ€§å‡½æ•°æ¥è¡¨ç¤ºã€‚</li>
</ul>
</li>
</ul>
<hr>
<h6 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a><strong>Dropout</strong></h6><ul>
<li><p>Each time before updating the parameters </p>
<ul>
<li><p>Each neuron has p% to dropout ï¼Œè®©æŸä¸ªç¥ç»å…ƒçš„æ¿€æ´»å€¼ä»¥ä¸€å®šçš„æ¦‚ç‡påœæ­¢å·¥ä½œï¼Œè¿™æ ·å¯ä»¥ä½¿æ¨¡å‹æ³›åŒ–æ€§æ›´å¼ºï¼Œå› ä¸ºå®ƒä¸ä¼šå¤ªä¾èµ–æŸäº›å±€éƒ¨çš„ç‰¹å¾</p>
<ul>
<li>The structure of the network is changed.  </li>
</ul>
</li>
<li><p>Using the new network for training</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/dropout1.png" alt="dropout1"></p>
</li>
</ul>
</li>
<li><p>For testingï¼š</p>
<ul>
<li>å¦‚æœè®­ç»ƒé›†çš„dropç‡ä¸ºp%ï¼Œåˆ™æµ‹è¯•é›†çš„ç¥ç»å…ƒæƒé‡è¾ƒè®­ç»ƒé›†åº”è¯¥ä¹˜ä¸Š(1-p%ï¼‰â€”â€”å› ä¸ºæµ‹è¯•é›†ä¸åšdrop</li>
</ul>
</li>
<li><p>Dropoutä¹‹åçš„ç½‘ç»œç»“æ„ä¸åŒï¼Œæ•…ä¼šè®­ç»ƒå‡ºä¸åŒçš„æ¨¡å‹ï¼Œé€šè¿‡averageå¯ä»¥å–å¾—æ›´å¥½çš„ç»“æœ</p>
</li>
<li><p>å¯ä»¥è§£å†³è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼š</p>
<ul>
<li>å‡å°‘ç¥ç»å…ƒä¹‹é—´å¤æ‚çš„å…±é€‚åº”å…³ç³»ï¼š å› ä¸ºä¸¤ä¸ªç¥ç»å…ƒä¸ä¸€å®šä¼šåŒæ—¶å‡ºç°åœ¨ä¸€ä¸ªç½‘ç»œé‡Œï¼Œæ•…æœ‰åˆ©äºåŠ å¼ºä»–ä»¬è‡ªèº«æ›´é²æ£’çš„å­¦ä¹ ã€‚</li>
<li>å–å¹³å‡çš„ä½œç”¨ï¼šç›¸å½“äºå¯¹å¾ˆå¤šä¸ªä¸åŒçš„ç¥ç»ç½‘ç»œå–å¹³å‡ã€‚è€Œä¸åŒçš„ç½‘ç»œäº§ç”Ÿä¸åŒçš„è¿‡æ‹Ÿåˆï¼Œä¸€äº›äº’ä¸ºâ€œåå‘â€çš„æ‹Ÿåˆç›¸äº’æŠµæ¶ˆå°±å¯ä»¥è¾¾åˆ°æ•´ä½“ä¸Šå‡å°‘è¿‡æ‹Ÿåˆã€‚</li>
</ul>
</li>
</ul>
<hr>
<h6 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a><strong>Network Structure</strong></h6><ul>
<li>æ¯”å¦‚CNN</li>
<li>â€¦â€¦</li>
</ul>
<hr>
<h4 id="Lecture-III-Variants-of-Neural-Networks"><a href="#Lecture-III-Variants-of-Neural-Networks" class="headerlink" title="Lecture III: Variants of Neural Networks"></a>Lecture III: Variants of Neural Networks</h4><ul>
<li><strong>Convolutional Neural Network (CNN)</strong>â€”â€”Widely used in image processing</li>
<li><strong>Recurrent Neural Network (RNN)</strong> </li>
</ul>
<hr>
<h5 id="Convolutional-Neural-Network-CNN"><a href="#Convolutional-Neural-Network-CNN" class="headerlink" title="Convolutional Neural Network (CNN)"></a><strong>Convolutional Neural Network (CNN)</strong></h5><ul>
<li><h6 id="Why-CNN-for-Imageï¼ˆsome-propertiesï¼‰"><a href="#Why-CNN-for-Imageï¼ˆsome-propertiesï¼‰" class="headerlink" title="Why CNN for Imageï¼ˆsome propertiesï¼‰"></a>Why CNN for Imageï¼ˆsome propertiesï¼‰</h6><ul>
<li>When processing image, the first layer of fully connected network would be very large </li>
<li>Some patterns are much smaller than the whole image</li>
<li>Subsampling the pixelsï¼ˆå‡å°åƒç´ ï¼‰ will not change the object</li>
</ul>
</li>
<li><h6 id="CNNçš„ç»“æ„"><a href="#CNNçš„ç»“æ„" class="headerlink" title="CNNçš„ç»“æ„"></a>CNNçš„ç»“æ„</h6><ul>
<li><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/CNNç½‘ç»œç»“æ„.png" alt="CNNç½‘ç»œç»“æ„"></li>
<li>Convolution:<ul>
<li>Some patterns are much smaller than the whole imageï¼ˆé€šè¿‡é¸Ÿçš„å–™å½¢åˆ¤æ–­é¸Ÿçš„å“ç§ï¼‰</li>
<li>The same patterns appear in different regions.ï¼ˆå‡ºç°åœ¨å›¾ç‰‡ä¸åŒä½ç½®çš„é¸Ÿå–™ï¼‰ </li>
</ul>
</li>
<li>Max Pooling:<ul>
<li>Subsampling the pixels will not change the object ï¼ˆå¯ä»¥å¯¹å›¾ç‰‡è¿›è¡Œç¼©æ”¾å¤„ç†ï¼Œå‡å°‘åƒç´ ç‚¹ï¼Œå‡å°‘ç½‘ç»œç»“æ„çš„å¤§é‡å‚æ•°ï¼‰</li>
</ul>
</li>
</ul>
</li>
<li><h6 id="Convolutionå·ç§¯å±‚"><a href="#Convolutionå·ç§¯å±‚" class="headerlink" title="Convolutionå·ç§¯å±‚"></a>Convolutionå·ç§¯å±‚</h6><ul>
<li><p>å·ç§¯æ ¸ï¼ˆä¸¾ä¾‹ï¼‰</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/å·ç§¯æ ¸.png" alt="å·ç§¯æ ¸"></p>
</li>
<li><p>è¾“å…¥å›¾åƒä¿¡æ¯ï¼ˆä¸¾ä¾‹ï¼‰</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/å·ç§¯-è¾“å…¥.png" alt="å·ç§¯-è¾“å…¥"></p>
</li>
<li><p>å·ç§¯çš„æ“ä½œ</p>
<ul>
<li><p>æ­¥é•¿ï¼šæ§åˆ¶å·ç§¯æ ¸ç§»åŠ¨çš„è·ç¦»</p>
<ul>
<li><p>ä½¿ç”¨filter 1ï¼Œæ­¥é•¿ä¸º1 stride=1</p>
<p>â€‹    <img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/slide1.png" alt="slide1"></p>
</li>
<li><p>ä½¿ç”¨filter 1ï¼Œæ­¥é•¿ä¸º2 stride=2ï¼ˆä»…ç¤ºä¾‹ï¼Œä¸‹é¢ç»“æœå‡ä½¿ç”¨æ­¥é•¿ä¸º1ï¼‰</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/slide2.png" alt="slide2"></p>
</li>
<li><p>ç›—ä¸€ä¸ªåŠ¨å›¾ï¼ˆä¸ä¸Šé¢çš„æ•°æ®ä¸åŒï¼Œä½†æ˜¯æ–¹ä¾¿ç†è§£ï¼‰</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/pk2y72bp1x.gif" alt="pk2y72bp1x"></p>
</li>
<li><p>filter 1 å¤„ç†ç»“æŸåçš„ç»“æœ</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/å·ç§¯filter1.png" alt="å·ç§¯filter1"></p>
</li>
<li><p>ä½¿ç”¨filter 2åŒæ ·å·ç§¯å¤„ç†åçš„ç»“æœ</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/2filter.png" alt="2filter"></p>
</li>
</ul>
</li>
<li><p>Paddingå¡«å……ï¼šå¯¹æ•°æ®åšçš„æ“ä½œã€‚ä¸€èˆ¬æœ‰ä¸¤ç§ï¼Œä¸€ç§æ˜¯ä¸è¿›è¡Œæ“ä½œï¼Œä¸€ç§æ˜¯è¡¥0ä½¿å¾—å·ç§¯åçš„æ¿€æ´»æ˜ å°„å°ºå¯¸ä¸å˜ã€‚</p>
<ul>
<li><p>Zero Paddingé›¶å¡«å……ï¼šæœ‰æ—¶ï¼Œåœ¨è¾“å…¥çŸ©é˜µçš„è¾¹ç¼˜ä½¿ç”¨é›¶å€¼è¿›è¡Œå¡«å……ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¯¹è¾“å…¥å›¾åƒçŸ©é˜µçš„è¾¹ç¼˜è¿›è¡Œæ»¤æ³¢ã€‚é›¶å¡«å……çš„ä¸€å¤§å¥½å¤„æ˜¯å¯ä»¥è®©æˆ‘ä»¬æ§åˆ¶ç‰¹å¾å›¾çš„å¤§å°ã€‚ä½¿ç”¨é›¶å¡«å……çš„ä¹Ÿå«åšæ³›å·ç§¯ï¼Œä¸ä½¿ç”¨é›¶å¡«å……çš„å«åšä¸¥æ ¼å·ç§¯</p>
<ul>
<li><p>å…¨0å¡«å……çš„å«ä¹‰ï¼Œä¸æ˜¯åœ¨å³ï¼ˆä¸‹ï¼‰å¤šåŠ ä¸€è¡Œï¼ˆåˆ—ï¼‰0ã€‚å…·ä½“åŠ å¤šå°‘0è¦æ ¹æ®å®é™…æƒ…å†µå†³å®š</p>
</li>
<li><p>ä½¿ç”¨é›¶å¡«å……ä¹‹åå†ä½¿ç”¨filter è¿›è¡Œå·ç§¯å¯ä»¥ä½¿å¾—è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦ç›¸åŒ</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/é›¶å¡«å…….png" alt="é›¶å¡«å……"></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>å…¶å®æˆ‘ä»¬è¾“å…¥çš„å›¾åƒä¸€èˆ¬ä¸ºä¸‰ç»´ï¼Œå³å«æœ‰Rã€Gã€Bä¸‰ä¸ªé€šé“ã€‚ä½†å…¶å®ç»è¿‡ä¸€ä¸ªå·ç§¯æ ¸ä¹‹åï¼Œä¸‰ç»´ä¼šå˜æˆä¸€ç»´ã€‚å®ƒåœ¨ä¸€æ•´ä¸ªå±å¹•æ»‘åŠ¨çš„æ—¶å€™ï¼Œå…¶å®ä¼šæŠŠä¸‰ä¸ªé€šé“çš„å€¼éƒ½ç´¯åŠ èµ·æ¥ï¼Œæœ€ç»ˆåªæ˜¯è¾“å‡ºä¸€ä¸ªä¸€ç»´çŸ©é˜µã€‚</p>
</li>
</ul>
</li>
</ul>
</li>
<li><h6 id="Poolingæ± åŒ–å±‚-æ± åŒ–å±‚ä¸€èˆ¬æ”¾åœ¨å·ç§¯å±‚åé¢ã€‚æ‰€ä»¥æ± åŒ–å±‚çš„è¾“å…¥æ˜¯å·ç§¯å±‚çš„è¾“å‡º"><a href="#Poolingæ± åŒ–å±‚-æ± åŒ–å±‚ä¸€èˆ¬æ”¾åœ¨å·ç§¯å±‚åé¢ã€‚æ‰€ä»¥æ± åŒ–å±‚çš„è¾“å…¥æ˜¯å·ç§¯å±‚çš„è¾“å‡º" class="headerlink" title="Poolingæ± åŒ–å±‚(æ± åŒ–å±‚ä¸€èˆ¬æ”¾åœ¨å·ç§¯å±‚åé¢ã€‚æ‰€ä»¥æ± åŒ–å±‚çš„è¾“å…¥æ˜¯å·ç§¯å±‚çš„è¾“å‡º)"></a>Poolingæ± åŒ–å±‚(æ± åŒ–å±‚ä¸€èˆ¬æ”¾åœ¨å·ç§¯å±‚åé¢ã€‚æ‰€ä»¥æ± åŒ–å±‚çš„è¾“å…¥æ˜¯å·ç§¯å±‚çš„è¾“å‡º)</h6><ul>
<li>æ± åŒ–å±‚ä¹Ÿæœ‰paddingçš„é€‰é¡¹ã€‚è·Ÿå·ç§¯å±‚ä¸€æ ·çš„ï¼Œåœ¨å¤–å›´è¡¥0ï¼Œç„¶åå†æ± åŒ–ã€‚</li>
<li>æœ€å¤§æ± åŒ– max-poolingï¼ˆæ›´å¸¸ç”¨ï¼‰<ul>
<li>ä¸ºäº†æå–æœ€æ˜æ˜¾çš„ç‰¹å¾</li>
<li><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/max-pooling.png" alt="max-pooling"></li>
</ul>
</li>
<li>å¹³å‡æ± åŒ– mean-pooling<ul>
<li>é¡¾åŠæ¯ä¸€ä¸ªåƒç´ ï¼Œæ‰€ä»¥é€‰æ‹©å°†æ‰€æœ‰çš„åƒç´ å€¼éƒ½ç›¸åŠ ç„¶åå†å¹³å‡</li>
<li>å³æ¯ä¸ªfilterå–å¹³å‡å€¼</li>
</ul>
</li>
</ul>
</li>
<li><h6 id="Flattenï¼ˆæ‰å¹³åŒ–ï¼‰"><a href="#Flattenï¼ˆæ‰å¹³åŒ–ï¼‰" class="headerlink" title="Flattenï¼ˆæ‰å¹³åŒ–ï¼‰"></a>Flattenï¼ˆæ‰å¹³åŒ–ï¼‰</h6><ul>
<li>Flattenå±‚ç”¨æ¥å°†è¾“å…¥â€œå‹å¹³â€ï¼Œå³æŠŠå¤šç»´çš„è¾“å…¥ä¸€ç»´åŒ–ï¼Œå¸¸ç”¨åœ¨ä»å·ç§¯å±‚åˆ°å…¨è¿æ¥å±‚çš„è¿‡æ¸¡ã€‚Flattenä¸å½±å“batchçš„å¤§å°ã€‚</li>
</ul>
</li>
<li><h6 id="BPç®—æ³•ï¼ˆerror-BackPropagationï¼‰æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œæœ€ä¸ºç»å…¸çš„ç®—æ³•"><a href="#BPç®—æ³•ï¼ˆerror-BackPropagationï¼‰æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œæœ€ä¸ºç»å…¸çš„ç®—æ³•" class="headerlink" title="BPç®—æ³•ï¼ˆerror BackPropagationï¼‰æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œæœ€ä¸ºç»å…¸çš„ç®—æ³•"></a>BPç®—æ³•ï¼ˆerror BackPropagationï¼‰æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œæœ€ä¸ºç»å…¸çš„ç®—æ³•</h6><ul>
<li>åŸºäºæ¢¯åº¦ä¸‹é™</li>
</ul>
</li>
</ul>
<hr>
<h5 id="Recurrent-Neural-Network-RNN-å¾ªç¯ç¥ç»ç½‘ç»œ"><a href="#Recurrent-Neural-Network-RNN-å¾ªç¯ç¥ç»ç½‘ç»œ" class="headerlink" title="Recurrent Neural Network (RNN)å¾ªç¯ç¥ç»ç½‘ç»œ"></a>Recurrent Neural Network (RNN)å¾ªç¯ç¥ç»ç½‘ç»œ</h5><ul>
<li><p>Slot Filling</p>
<ul>
<li>å¡«æ§½(<em>Slot</em> <em>filling</em>)æŒ‡çš„æ˜¯ä¸ºäº†è®©ç”¨æˆ·æ„å›¾è½¬åŒ–ä¸ºç”¨æˆ·æ˜ç¡®çš„æŒ‡ä»¤è€Œè¡¥å…¨ä¿¡æ¯çš„è¿‡ç¨‹</li>
</ul>
</li>
<li><p>æ¯”å¦‚åœ¨ä¸€ä¸ªè®¢ç¥¨ç³»ç»Ÿä¸Šï¼Œæˆ‘ä»¬çš„è¾“å…¥ â€œArrive Taipei on November 2ndâ€ è¿™æ ·ä¸€ä¸ªåºåˆ—ï¼Œæˆ‘ä»¬è®¾ç½®å‡ ä¸ªæ§½ä½ï¼ˆSlotï¼‰ï¼Œå¸Œæœ›ç®—æ³•èƒ½å¤Ÿå°†å…³é”®è¯â€™Taipeiâ€™æ”¾å…¥ç›®çš„åœ°ï¼ˆDestinationï¼‰æ§½ä½ï¼Œå°†Novemberå’Œ2ndæ”¾å…¥åˆ°è¾¾æ—¶é—´ï¼ˆTime of Arrivalï¼‰æ§½ä½ï¼Œå°†Arriveå’Œonæ”¾å…¥å…¶ä»–ï¼ˆOtherï¼‰æ§½ä½ï¼Œå®ç°å¯¹è¾“å…¥åºåˆ—çš„ä¸€ä¸ªå½’ç±»ï¼Œä»¥ä¾¿åç»­æå–ç›¸åº”ä¿¡æ¯ã€‚</p>
<ul>
<li>ç”¨å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆFeedforward Neural Networkï¼‰æ¥è§£å†³è¿™ä¸ªé—®é¢˜çš„è¯ï¼Œæˆ‘ä»¬é¦–å…ˆè¦å¯¹è¾“å…¥åºåˆ—å‘é‡åŒ–ï¼Œå°†æ¯ä¸€ä¸ªè¾“å…¥çš„å•è¯ç”¨å‘é‡è¡¨ç¤ºï¼Œå¯ä»¥ä½¿ç”¨ One-of-N Encoding æˆ–è€…æ˜¯ Word hashing ç­‰ç¼–ç æ–¹æ³•ï¼Œè¾“å‡ºé¢„æµ‹æ§½ä½çš„æ¦‚ç‡åˆ†å¸ƒã€‚</li>
</ul>
</li>
<li><p>ä½†æ˜¯è¿™æ ·åšçš„è¯ï¼Œæœ‰ä¸ªé—®é¢˜å°±å‡ºç°äº†ã€‚å¦‚æœç°åœ¨åˆæœ‰ä¸€ä¸ªè¾“å…¥æ˜¯ â€œLeave Taipei on November 2ndâ€ï¼Œè¿™é‡ŒTaipeiæ˜¯ä½œä¸ºä¸€ä¸ªå‡ºå‘åœ°ï¼ˆPlace of Departureï¼‰ï¼Œæ‰€ä»¥æˆ‘ä»¬åº”å½“æ˜¯æŠŠTaipeiæ”¾å…¥Departureæ§½ä½è€Œä¸æ˜¯Destination æ§½ä½ï¼Œå¯æ˜¯å¯¹äºå‰é¦ˆç½‘ç»œæ¥è¯´ï¼Œå¯¹äºåŒä¸€ä¸ªè¾“å…¥ï¼Œè¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒåº”è¯¥ä¹Ÿæ˜¯ä¸€æ ·çš„ï¼Œä¸å¯èƒ½å‡ºç°æ—¢æ˜¯Destinationçš„æ¦‚ç‡æœ€é«˜åˆæ˜¯Departureçš„æ¦‚ç‡æœ€é«˜ã€‚</p>
</li>
<li><p>æ‰€ä»¥æˆ‘ä»¬å°±å¸Œæœ›èƒ½å¤Ÿè®©ç¥ç»ç½‘ç»œæ‹¥æœ‰â€œ<strong>è®°å¿†</strong>â€çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ ¹æ®ä¹‹å‰çš„ä¿¡æ¯ï¼ˆåœ¨è¿™ä¸ªä¾‹å­ä¸­æ˜¯Arriveæˆ–Leaveï¼‰ä»è€Œå¾—åˆ°ä¸åŒçš„è¾“å‡ºã€‚å°†ä¸¤æ®µåºåˆ—ä¸­çš„Taipeiåˆ†åˆ«å½’å…¥Destionationæ§½ä½å’ŒDepartureæ§½ä½ã€‚</p>
</li>
<li><p>RNN</p>
<ul>
<li><p>The output of hidden layer are stored in the memory.</p>
</li>
<li><p>Memory can be considered as another input.</p>
</li>
<li><p>The same network is used again and again.</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/rnn-slot.png" alt="rnn-slot"></p>
</li>
<li><p>æ•´ä½“ç»“æ„</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/rnn-str.png" alt="rnn-str"></p>
</li>
</ul>
</li>
<li><p>Bidirectional RNNï¼ˆåŒå‘rnnï¼‰</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/bi-rnn.png" alt="bi-rnn"></p>
</li>
<li><p>Long Short-term Memory (LSTM)</p>
<ul>
<li><p>ç»“æ„ï¼š</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/lstm-str.png" alt="lstm-str"></p>
</li>
<li><p>å‚æ•°ç»“æ„ï¼š</p>
<p><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/lstm-pa.png" alt="lstm-pa"></p>
<ul>
<li>ç”±Memory Cellï¼Œ Input Gateï¼Œ Output Gateï¼Œ Forget Gate ç»„æˆ</li>
<li>ç‰¹æ®Šçš„ç¥ç»å…ƒç»“æ„ï¼ŒåŒ…å«4ä¸ªinputï¼ˆä¸‰ä¸ªGateçš„æ§åˆ¶ä¿¡å·ä»¥åŠè¾“å…¥çš„æ•°æ®ï¼‰ï¼Œ1ä¸ªoutput</li>
<li>æ¿€æ´»å‡½æ•°é€šå¸¸é€‰ç”¨sigmoid functionï¼Œ sigmoidçš„è¾“å‡ºä»‹äº0åˆ°1ä¹‹é—´ï¼Œè¡¨å¾äº†Gateçš„æ‰“å¼€ç¨‹åº¦</li>
<li>Short-termï¼Œè¡¨ç¤ºä¿ç•™å¯¹å‰ä¸€æ—¶é—´ç‚¹è¾“å‡ºçš„çŸ­æœŸè®°å¿†ï¼Œç›¸æ¯”äºæœ€åŸå§‹çš„RNNç»“æ„ä¸­çš„è®°å¿†å•å…ƒï¼ˆæ¯æ¬¡æœ‰æ–°çš„è¾“å…¥æ—¶è®°å¿†ä½“çš„çŠ¶æ€å°±ä¼šè¢«æ›´æ–°ï¼Œå› æ­¤æ˜¯çŸ­æœŸçš„è®°å¿†ï¼‰ï¼ŒLSTMçš„è®°å¿†ä½“æ‹¥æœ‰ç›¸å¯¹è¾ƒé•¿çš„è®°å¿†æ—¶é—´ï¼ˆç”±Forget Gateå†³å®šï¼‰ï¼Œæ‰€ä»¥æ˜¯Long Short-term</li>
</ul>
</li>
</ul>
</li>
<li><p>å­¦ä¹ /è®­ç»ƒè¿‡ç¨‹ to pick the best function </p>
<ul>
<li>æŸå¤±å‡½æ•°<ul>
<li>æ¯ä¸€ä¸ªæ—¶é—´ç‚¹çš„RNNçš„è¾“å‡ºå’Œæ ‡ç­¾å€¼çš„äº¤å‰ç†µï¼ˆcross-entropyï¼‰ä¹‹å’Œ</li>
</ul>
</li>
<li>ä½¿ç”¨è¢«ç§°ä½œBackpropagation through timeï¼ˆBPTTï¼‰çš„æ¢¯åº¦ä¸‹é™æ³•</li>
<li>è®­ç»ƒå…¶å®æ˜¯æ¯”è¾ƒå›°éš¾çš„ï¼Œå› ä¸ºTotal Losså¯èƒ½ä¼šå‡ºç°å‰§çƒˆçš„æŠ–åŠ¨<ul>
<li>æŸå¤±å‡½æ•°çš„è¡¨é¢è¦ä¹ˆéå¸¸å¹³å¦ï¼Œè¦ä¹ˆéå¸¸é™¡å³­</li>
<li>åŸå› ï¼š</li>
<li>ä¸æ¿€æ´»å‡½æ•°æ˜¯Sigmoidæˆ–è€…ReLUæ— å…³</li>
<li>ç”±äºRNNé‡‡ç”¨æ—¶é—´åºåˆ—çš„ç»“æ„ï¼Œæƒé‡å€¼åœ¨ä¸åŒæ—¶é—´ç‚¹è¢«åå¤ä½¿ç”¨ï¼Œè¿™ç§ç´¯ç§¯æ€§çš„å˜åŒ–å¯èƒ½å¯¹ç»“æœé€ æˆæå¤§çš„å½±å“ï¼Œä¹Ÿå¯èƒ½ä¼šå¾ˆé•¿ä¸€æ®µæ—¶é—´ä¿æŒå¹³ç¨³ã€‚ï¼ˆ$1^{1000}=1;1.01^{1000}-&gt;20000$ï¼‰</li>
</ul>
</li>
<li>å¤„ç†æ–¹æ³•ï¼š<ul>
<li>LSTM<ul>
<li>å¯ä»¥å¤„ç†æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼ˆä¸èƒ½å¤„ç†æ¢¯åº¦çˆ†ç‚¸ï¼‰â€”â€”åªæœ‰åœ¨é—å¿˜é—¨å…³æ‰çš„æ—¶å€™è®°å¿†å•å…ƒçš„å€¼æ‰ä¼šå¯¹è¾“å‡ºå¤±å»å½±å“</li>
<li>å¯èƒ½ä¼šå¼•èµ·æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜</li>
</ul>
</li>
<li>GRU(Gated Recurrent Unit)</li>
</ul>
</li>
</ul>
</li>
<li><p>åº”ç”¨</p>
<ul>
<li>å¤šå¯¹ä¸€ Input is a vector sequence, but output is only one vector<ul>
<li>æƒ…æ„Ÿåˆ†æ</li>
</ul>
</li>
<li>å¤šå¯¹å¤šBoth input and output are both sequences,<ul>
<li>but the output is shorter<ul>
<li>è¯­éŸ³è¯†åˆ«</li>
<li>CTC</li>
</ul>
</li>
<li>with different lengths. <ul>
<li>æœºå™¨ç¿»è¯‘</li>
</ul>
</li>
</ul>
</li>
<li>ä¸€å¯¹å¤š Input an image, but output a sequence of words<ul>
<li>å­—å¹•ç”Ÿæˆ</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="Lecture-IV-Next-Wave"><a href="#Lecture-IV-Next-Wave" class="headerlink" title="Lecture IV: Next Wave"></a>Lecture IV: Next Wave</h4><ul>
<li><strong>Supervised Learning</strong></li>
<li><strong>Reinforcement Learning</strong></li>
<li><strong>Unsupervised Learning</strong><ul>
<li>Image: Realizing what the World Looks Like</li>
<li>Text: Understanding the Meaning of Words</li>
<li>Audio: Learning human language without supervision</li>
</ul>
</li>
</ul>
<hr>
<h5 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h5><ul>
<li><h6 id="Ultra-Deep-Networkè¶…æ·±ç½‘ç»œ"><a href="#Ultra-Deep-Networkè¶…æ·±ç½‘ç»œ" class="headerlink" title="Ultra Deep Networkè¶…æ·±ç½‘ç»œ"></a>Ultra Deep Networkè¶…æ·±ç½‘ç»œ</h6><ul>
<li>Ultra deep network is the ensemble of many networks with different depth. </li>
<li>FractalNet<ul>
<li>Ultra Deep Network without residuals</li>
<li><img src="/2019/09/10/å­¦ä¹ /book/Deep-Learning-Tutorial-æå®æ¯…/Ultra-deep.png" alt="Ultra-deep"></li>
<li>Highway Network automatically determines the layers needed</li>
</ul>
</li>
</ul>
</li>
<li><h6 id="Attention-based-Model"><a href="#Attention-based-Model" class="headerlink" title="Attention-based Model"></a>Attention-based Model</h6><ul>
<li>Reading Comprehension</li>
</ul>
</li>
</ul>
<hr>
<h6 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h6><ul>
<li>Learning from critics</li>
<li>Supervised Learning<ul>
<li>Learning from teacher </li>
</ul>
</li>
<li>Difficulties <ul>
<li>It may be better to sacrifice immediate reward to gain more long-term reward</li>
<li>Agentâ€™s actions affect the subsequent data it receives </li>
</ul>
</li>
<li>Application: Interactive Retrievaläº¤äº’å¼æ£€ç´¢</li>
</ul>
<hr>
<h6 id="unsupervised-Leadning"><a href="#unsupervised-Leadning" class="headerlink" title="unsupervised Leadning"></a>unsupervised Leadning</h6><ul>
<li>Generating Images <ul>
<li>Auto-encoder</li>
</ul>
</li>
<li>Machine Reading<ul>
<li>Machine learn the meaning of words from reading a lot of documents without supervision</li>
<li>Generating Word Vector/Embedding is unsupervised</li>
</ul>
</li>
<li>Audio </li>
</ul>
<p>å‚è€ƒèµ„æ–™ï¼š</p>
<p><a href="https://www.maixj.net/ict/weight-decay-19860" target="_blank" rel="noopener">ç†è§£weight decay</a></p>
<p><a href="https://blog.csdn.net/program_developer/article/details/80737724" target="_blank" rel="noopener">æ·±åº¦å­¦ä¹ ä¸­DropoutåŸç†è§£æ</a></p>
<p><a href="https://blog.csdn.net/weixin_41417982/article/details/81412076" target="_blank" rel="noopener">å·ç§¯å±‚ä¸æ± åŒ–å±‚</a></p>
<p><a href="https://blog.csdn.net/u010159842/article/details/80760025" target="_blank" rel="noopener">Slot Fillingè¯¦ç»†è®²è§£</a></p>
<p><a href="https://blog.csdn.net/qq_39422642/article/details/78676567#" target="_blank" rel="noopener">å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰åŸç†é€šä¿—è§£é‡Š</a></p>

      
    </div>

    

    
    
    

    

    

    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------ã€€ã€€ã€€ã€€æœ¬æ–‡ç»“æŸã€€<i class="fa fa-heart"></i>ã€€æ„Ÿè°¢æ‚¨çš„é˜…è¯»ã€€ã€€ã€€ã€€-------------</div>
    
</div>
      
    </div>

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/09/10/å­¦ä¹ /book/æ·±åº¦å­¦ä¹ æ–‡æ¡£å­¦ä¹ ç¬”è®°/" rel="next" title="æ·±åº¦å­¦ä¹ æ–‡æ¡£å­¦ä¹ ç¬”è®°">
                <i class="fa fa-chevron-left"></i> æ·±åº¦å­¦ä¹ æ–‡æ¡£å­¦ä¹ ç¬”è®°
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/09/10/å­¦ä¹ /courses/æœºå™¨å­¦ä¹ -å´æ©è¾¾/" rel="prev" title="æœºå™¨å­¦ä¹ -å´æ©è¾¾">
                æœºå™¨å­¦ä¹ -å´æ©è¾¾ <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            æ–‡ç« ç›®å½•
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            ç«™ç‚¹æ¦‚è§ˆ
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/headimg/14.jpg"
                alt="Lavi" />
            
              <p class="site-author-name" itemprop="name">Lavi</p>
              <p class="site-description motion-element" itemprop="description">è¿›åŒ–ing</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">63</span>
                    <span class="site-state-item-name">æ—¥å¿—</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">åˆ†ç±»</span>
                  </a>
                </div>
              

              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/zlovey" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:937198813@qq.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#Lecture-I-Introduction-of-Deep-Learning"><span class="nav-number">1.</span> <span class="nav-text">Lecture I: Introduction of  Deep Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Introduction-of-Deep-Learning"><span class="nav-number">1.1.</span> <span class="nav-text">Introduction of Deep Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Three-Steps-for-Deep-Learning"><span class="nav-number">1.1.1.</span> <span class="nav-text">Three Steps for Deep Learning</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Why-Deep"><span class="nav-number">1.2.</span> <span class="nav-text">Why Deep?</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#â€œHello-Worldâ€-for-Deep-Learning"><span class="nav-number">1.3.</span> <span class="nav-text">â€œHello Worldâ€ for Deep Learning</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Lecture-II-Tips-for-Training-DNN"><span class="nav-number">2.</span> <span class="nav-text">Lecture II: Tips for Training DNN</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Good-Results-on-Training-Data"><span class="nav-number">2.1.</span> <span class="nav-text">Good Results on Training Data?</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Choosing-proper-loss"><span class="nav-number">2.1.1.</span> <span class="nav-text">Choosing proper loss</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Mini-batch"><span class="nav-number">2.1.2.</span> <span class="nav-text">Mini-batch</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#New-activation-function"><span class="nav-number">2.1.3.</span> <span class="nav-text">New activation function</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Adaptive-Learning-Rate"><span class="nav-number">2.1.4.</span> <span class="nav-text">Adaptive Learning Rate</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#MomentumåŠ¨é‡â€”â€”ä¸‹å¡"><span class="nav-number">2.1.5.</span> <span class="nav-text">MomentumåŠ¨é‡â€”â€”ä¸‹å¡</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Good-Results-on-Testing-Data"><span class="nav-number">2.2.</span> <span class="nav-text">Good Results on Testing Data?</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Overfitting"><span class="nav-number">2.2.1.</span> <span class="nav-text">Overfitting</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Early-Stopping"><span class="nav-number">2.2.2.</span> <span class="nav-text">Early Stopping</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Weight-Decay-regularization-L2æ­£åˆ™åŒ–"><span class="nav-number">2.2.3.</span> <span class="nav-text">Weight Decay(regularization  L2æ­£åˆ™åŒ–)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Dropout"><span class="nav-number">2.2.4.</span> <span class="nav-text">Dropout</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Network-Structure"><span class="nav-number">2.2.5.</span> <span class="nav-text">Network Structure</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Lecture-III-Variants-of-Neural-Networks"><span class="nav-number">3.</span> <span class="nav-text">Lecture III: Variants of Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Convolutional-Neural-Network-CNN"><span class="nav-number">3.1.</span> <span class="nav-text">Convolutional Neural Network (CNN)</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Why-CNN-for-Imageï¼ˆsome-propertiesï¼‰"><span class="nav-number">3.1.1.</span> <span class="nav-text">Why CNN for Imageï¼ˆsome propertiesï¼‰</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#CNNçš„ç»“æ„"><span class="nav-number">3.1.2.</span> <span class="nav-text">CNNçš„ç»“æ„</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Convolutionå·ç§¯å±‚"><span class="nav-number">3.1.3.</span> <span class="nav-text">Convolutionå·ç§¯å±‚</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Poolingæ± åŒ–å±‚-æ± åŒ–å±‚ä¸€èˆ¬æ”¾åœ¨å·ç§¯å±‚åé¢ã€‚æ‰€ä»¥æ± åŒ–å±‚çš„è¾“å…¥æ˜¯å·ç§¯å±‚çš„è¾“å‡º"><span class="nav-number">3.1.4.</span> <span class="nav-text">Poolingæ± åŒ–å±‚(æ± åŒ–å±‚ä¸€èˆ¬æ”¾åœ¨å·ç§¯å±‚åé¢ã€‚æ‰€ä»¥æ± åŒ–å±‚çš„è¾“å…¥æ˜¯å·ç§¯å±‚çš„è¾“å‡º)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Flattenï¼ˆæ‰å¹³åŒ–ï¼‰"><span class="nav-number">3.1.5.</span> <span class="nav-text">Flattenï¼ˆæ‰å¹³åŒ–ï¼‰</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#BPç®—æ³•ï¼ˆerror-BackPropagationï¼‰æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œæœ€ä¸ºç»å…¸çš„ç®—æ³•"><span class="nav-number">3.1.6.</span> <span class="nav-text">BPç®—æ³•ï¼ˆerror BackPropagationï¼‰æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œæœ€ä¸ºç»å…¸çš„ç®—æ³•</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Recurrent-Neural-Network-RNN-å¾ªç¯ç¥ç»ç½‘ç»œ"><span class="nav-number">3.2.</span> <span class="nav-text">Recurrent Neural Network (RNN)å¾ªç¯ç¥ç»ç½‘ç»œ</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Lecture-IV-Next-Wave"><span class="nav-number">4.</span> <span class="nav-text">Lecture IV: Next Wave</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Supervised-Learning"><span class="nav-number">4.1.</span> <span class="nav-text">Supervised Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Ultra-Deep-Networkè¶…æ·±ç½‘ç»œ"><span class="nav-number">4.1.1.</span> <span class="nav-text">Ultra Deep Networkè¶…æ·±ç½‘ç»œ</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Attention-based-Model"><span class="nav-number">4.1.2.</span> <span class="nav-text">Attention-based Model</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Reinforcement-Learning"><span class="nav-number">4.1.3.</span> <span class="nav-text">Reinforcement Learning</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#unsupervised-Leadning"><span class="nav-number">4.1.4.</span> <span class="nav-text">unsupervised Leadning</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lavi</span>

  

  
</div>


<!--

  <div class="powered-by">ç”± <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> å¼ºåŠ›é©±åŠ¨ v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">ä¸»é¢˜ &mdash; <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Gemini</a> v6.3.0</div>



-->
        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  













  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.3.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



  










  





  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  

  
  <script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":true,"debug":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":70,"height":140},"mobile":{"show":true},"log":false});</script>
</body>
</html>
